
<div id="top">

# Embodied-interactive-cognition

> **This repo is all you need for embodied interactive cognition research.** We present awesome talks, comprehensive paper collections, benchmarks, and challenges.

<!-- ![](https://img.shields.io/badge/Record-137-673ab7.svg)
![](https://img.shields.io/badge/License-MIT-lightgrey.svg) -->

## Table of Contents

- [Survey and similarity framework](#survey-and-similarity-framework)
- - [Survey](#survey)
- - [Similarity framework](#similarity-framework)
- [Embodied](#embodied)
- - [Embodied interaction](#embodied-interaction)
- - [Embodied intelligence](#embodied-intelligence)
- [Interactive or cognitive](#interactive-or-cognitive)
- - [Human-vehicle interaction](#human-vehicle-interaction)
- - [Vehicle-vehicle interaction](#vehicle-vehicle-interaction)
- - [Human-robot interaction](#human-robot-interaction)
- - [Interaction framework](#interaction-framework)
- - - [Co-leader planning](#co-leader-planning)
- - - [Human leader](#human-leader)
- - - [Joint planning](#joint-planning)
- - - [Robot leader](#robot-leader)
- [Self-driving](#self-driving)
- - [Cross-modal perception](#cross-modal-perception)
- - [Hypergraph learning](#hypergraph-learning)
- - [Large language model](#large-language-model)
- [Datasets](#datasets)
- [Others](#others)
- - [Transformer](#transformer)
- - [Cognition](#cognition)

## Survey and similarity framework

### Survey
<!-- <details><summary>(Click for details)</summary> -->

- How should autonomous vehicles drive? Policy, methodological, and social considerations for designing a driver [[Humanities and social sciences communications, 2022]](https://www.nature.com/articles/s41599-022-01286-2)

- Self-driving cars: A city perspective [[Science robotics, 2019]](https://www.science.org/doi/full/10.1126/scirobotics.aav9843)

- Autonomous vehicles: An imperfect path to saving Amillions of lives [[Science robotics, 2019]](https://www.science.org/doi/full/10.1126/scirobotics.aaw8703)

- Computing Systems for Autonomous Driving: State of the Art and Challenges[[IEEE Internet of Things Journal, 2020]](https://ieeexplore.ieee.org/abstract/document/9288755)
  
- Social Interactions for Autonomous Driving: A Review and Perspectives [[Foundations and Trends® in Robotics, 2022]](https://www.nowpublishers.com/article/DownloadSummary/ROB-078)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Similarity framework

<!-- <details><summary>(Click for details)</summary> -->

- Planning-oriented Autonomous Driving[[CVPR, 2023]](https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Planning-Oriented_Autonomous_Driving_CVPR_2023_paper.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Embodied
  
### Embodied interaction

<!-- <details><summary>(Click for details)</summary> -->

- Seek opportunities for embodied and tangible interaction 
  
- Introduction to the Special Issue on the Theory and Practice of Embodied Interaction in HCI and Interaction Design[[ACM Transactions on Computer-Human Interaction (TOCHI), 2013]](https://www.researchgate.net/profile/Alissa-Antle/publication/262176023_Introduction_to_the_Special_Issue_on_the_Theory_and_Practice_of_Embodied_Interaction_in_HCI_and_Interaction_Design/links/54e5139a0cf29865c335fa74/Introduction-to-the-Special-Issue-on-the-Theory-and-Practice-of-Embodied-Interaction-in-HCI-and-Interaction-Design.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Embodied intelligence

<!-- <details><summary>(Click for details)</summary> -->

- Embodied intelligence via learning and evolution [[Nature communications，2021]](https://www.nature.com/articles/s41467-021-25874-z)
  
- A concise guide to modelling the physics of embodied intelligence in soft robotics [[Nature Reviews Physics, 2022]](https://inria.hal.science/hal-03921606/document)
  
- Self-Organization, Embodiment, and Biologically Inspired Robotics[[science, 2007]](http://people.csail.mit.edu/iida/papers/PfeferEtAlScience2007.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>
  
## Interactive or Cognitive

### Human-vehicle interaction

<!-- <details><summary>(Click for details)</summary> -->

- Human–Vehicle Cooperation in Automated Driving: A Multidisciplinary Review and Appraisal [[International Journal of Human–Computer Interaction, 2019]](https://www.researchgate.net/profile/Francesco-Biondi/publication/330608900_Human-Vehicle_Cooperation_in_Automated_Driving_A_Multidisciplinary_Review_and_Appraisal/links/5f3beab492851cd30201915b/Human-Vehicle-Cooperation-in-Automated-Driving-A-Multidisciplinary-Review-and-Appraisal.pdf)

- "What Makes a Cooperative Driver?” Identifying parameters of implicit and explicit forms of communication in a lane change scenario[[Transportation Research Part F: Traffic Psychology and Behaviour]](https://www.sciencedirect.com/science/article/abs/pii/S1369847818302183)
  
- Parallel testing of vehicle intelligence via virtual-real interaction [[Science robotics, 2019]](https://www.science.org/doi/abs/10.1126/scirobotics.aaw4106)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Vehicle-vehicle interaction

<!-- <details><summary>(Click for details)</summary> -->

- Online legal driving behavior monitoring for self-driving vehicles [[Nature communications, 2024]](https://www.nature.com/articles/s41467-024-44694-5)
- Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving[[CVPR, 2024]](https://arxiv.org/pdf/2311.17918.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Human-robot interaction

<!-- <details><summary>(Click for details)</summary> -->

- A meta-analysis on the effectiveness of anthropomorphism in human-robot interaction [[Science Robotics, 2021]](https://www.researchgate.net/profile/Eileen-Roesler/publication/354457451_A_meta-Analysis_on_the_effectiveness_of_anthropomorphism_in_human-robot_interaction/links/615a94b8e7bb415a5d5f425f/A-meta-Analysis-on-the-effectiveness-of-anthropomorphism-in-human-robot-interaction.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Interaction framework

#### Co-leader planning

** This approach plans a policy modelled to both influence and be influenced by the stochastic behavior of the human.

<!-- <details><summary>(Click for details)</summary> -->

- Contingencies from Observations Tractable Contingency planning with learned behavior models[[ICRA, 2021]](https://arxiv.org/pdf/2104.10558)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

#### Human leader

** The plan is based on the forecasted behavior of SVs.

<!-- <details><summary>(Click for details)</summary> -->


<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

#### Joint leader

** Agents notice each other and global optimization.

<!-- <details><summary>(Click for details)</summary> -->


<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

#### Robot leader

** Predictions of other humans (pedestrians and drivers) are based on the robot's action

<!-- <details><summary>(Click for details)</summary> -->


<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Self-driving

### Cross-modal perception

<!-- <details><summary>(Click for details)</summary> -->

- TOFG: A Unified and Fine-Grained Environment Representation in Autonomous Driving[[arXiv preprint arXiv:2305.20068, 2023]](https://arxiv.org/pdf/2305.20068)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Hypergraph learning

<!-- <details><summary>(Click for details)</summary> -->

- Hypergraph Learning: Methods and Practices[[IEEE Transactions on Pattern Analysis and Machine Intelligence, 2020]](https://ieeexplore.ieee.org/abstract/document/9264674/)

- HGNN+: General Hypergraph Neural Networks[[IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022]](https://ieeexplore.ieee.org/abstract/document/9795251/)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Large language models

<!-- <details><summary>(Click for details)</summary> -->

- Language Models are Few-Shot Learners[[NEURIPS, 2020]](https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)

- A Language Agent for Autonomous Driving[[arXiv preprint arXiv:2311.10813, 2023]](https://arxiv.org/pdf/2311.10813)

- Experimental evidence on the productivity effects of generative artificial intelligence[[SSRN 4375283, 2023]](https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1_0.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Datasets


<p align="right">(<a href="#top">back to top</a>)</p>

## Others

### Transformer

<!-- <details><summary>(Click for details)</summary> -->

- Attention Is All You Need[[NEURIPS, 2017]](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Cognition

<!-- <details><summary>(Click for details)</summary> -->

- Metacognition ideas and insights from neuro- and educational sciences[[Science of Learning, 2021]](https://www.nature.com/articles/s41539-021-00089-5)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>



