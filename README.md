
<div id="top">

# Embodied-interactive-cognition

> **This repo is all you need for embodied interactive cognition research.** We present awesome talks, comprehensive paper collections, benchmarks, and challenges.

<!-- ![](https://img.shields.io/badge/Record-137-673ab7.svg)
![](https://img.shields.io/badge/License-MIT-lightgrey.svg) -->

## Table of Contents

- [Survey and similarity framework](#survey-and-similarity-framework)
- - [Survey](#survey)
- - [Similarity framework](#similarity-framework)
- [Embodied](#embodied)
- - [Embodied interaction](#embodied-interaction)
- - [Embodied intelligence](#embodied-intelligence)
- [Interactive or cognitive](#interactive-or-cognitive)
- - [Human-vehicle interaction](#human-vehicle-interaction)
- - [Vehicle-vehicle interaction](#vehicle-vehicle-interaction)
- - [Human-robot interaction](#human-robot-interaction)
- [Self-driving](#self-driving)
- [Datasets](#datasets)
- [Others](#others) 

## Survey and similarity framework

We list key challenges from a wide span of candidate concerns, as well as trending methodologies.

### Survey
<!-- <details><summary>(Click for details)</summary> -->

- How should autonomous vehicles drive? Policy, methodological, and social considerations for designing a driver [[arXiv2023]](https://arxiv.org/abs/2306.16927)

- Self-driving cars: A city perspective [[TIV2023]](https://ieeexplore.ieee.org/abstract/document/10258330)

- Autonomous vehicles: An imperfect path to saving Amillions of lives [[arXiv2023]](https://arxiv.org/abs/2308.05731)

- Computing Systems for Autonomous Driving: State of the Art and Challenges
  
- Social Interactions for Autonomous Driving: A Review and Perspectives

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Similarity framework

<!-- <details><summary>(Click for details)</summary> -->

- Planning-oriented Autonomous Driving

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Embodied
  
### Embodied interaction

<!-- <details><summary>(Click for details)</summary> -->

- Seek opportunities for embodied and tangible interaction [[TIV2023]](https://ieeexplore.ieee.org/abstract/document/10258330)
- Introduction to the Special Issue on the Theory and Practice of Embodied Interaction in HCI and Interaction Design

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Embodied intelligence

<!-- <details><summary>(Click for details)</summary> -->

- Embodied intelligence via learning and evolution [[TIV2023]](https://ieeexplore.ieee.org/abstract/document/10258330)
- A concise guide to modelling the physics of embodied intelligence in soft robotics
- Self-Organization, Embodiment, and Biologically Inspired Robotics

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>
  
## Interactive or Cognitive

### Human-vehicle interaction

<!-- <details><summary>(Click for details)</summary> -->

- Human–Vehicle Cooperation in Automated Driving: A Multidisciplinary Review and Appraisal [[arXiv2023]](https://arxiv.org/abs/2306.16927)

- "What Makes a Cooperative Driver?” Identifying parameters of implicit and explicit forms of communication in a lane change scenario [[TIV2023]](https://ieeexplore.ieee.org/abstract/document/10258330)

- Parallel testing of vehicle intelligence via virtual-real interaction [[arXiv2023]](https://arxiv.org/abs/2308.05731)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Vehicle-vehicle interaction

<!-- <details><summary>(Click for details)</summary> -->

- Online legal driving behavior monitoring for self-driving vehicles [[arXiv2023]](https://arxiv.org/abs/2306.16927)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Human-robot interaction

<!-- <details><summary>(Click for details)</summary> -->

- A meta-analysis on the effectiveness of anthropomorphism in human-robot interaction [[TIV2023]](https://ieeexplore.ieee.org/abstract/document/10258330)

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Self-driving

### Cross-modal perception

<!-- <details><summary>(Click for details)</summary> -->

- TOFG: A Unified and Fine-Grained Environment Representation in Autonomous Driving

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Hypergraph learning

<!-- <details><summary>(Click for details)</summary> -->

- Hypergraph Learning: Methods and Practices

- HGNN+: General Hypergraph Neural Networks

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Large language models

<!-- <details><summary>(Click for details)</summary> -->

- Language Models are Few-Shot Learners

- A Language Agent for Autonomous Driving

- Experimental evidence on the productivity effects of generative artificial intelligence

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

### Transformer

<!-- <details><summary>(Click for details)</summary> -->

- Attention Is All You Need

<!-- </details> -->

<p align="right">(<a href="#top">back to top</a>)</p>

## Datasets


<p align="right">(<a href="#top">back to top</a>)</p>

## Others



<p align="right">(<a href="#top">back to top</a>)</p>
